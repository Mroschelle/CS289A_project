{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mroschelle/CS289A_project/blob/main/ColabGPU_289_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrvvwZUGE4b5"
      },
      "source": [
        "# Colab GPU Acceleration Setup Guide\n",
        "\n",
        "**First, make a copy of this notebook for yourself so that you can make edits. \"File\" -> \"Save a copy in Drive\"**\n",
        "\n",
        "Above select the \"Runtime\" dropdown -> \"Change runtime type\". You should use Python 3, and \"hardware accelerator\" should be \"GPU\".\n",
        "\n",
        "The following code cell will ensure that you have the GPU enabled. It will also provide system specifications. You should see something similar (with possibly different specs) as:\n",
        "\n",
        "```\n",
        "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-d977e794-801c-3a65-2cd2-2fe83043d501)\n",
        "Wed Apr  8 23:17:24 2020       \n",
        "+-----------------------------------------------------------------------------+\n",
        "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
        "|-------------------------------+----------------------+----------------------+\n",
        "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
        "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
        "|===============================+======================+======================|\n",
        "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
        "| N/A   33C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
        "+-------------------------------+----------------------+----------------------+\n",
        "                                                                               \n",
        "+-----------------------------------------------------------------------------+\n",
        "| Processes:                                                       GPU Memory |\n",
        "|  GPU       PID   Type   Process name                             Usage      |\n",
        "|=============================================================================|\n",
        "|  No running processes found                                                 |\n",
        "+-----------------------------------------------------------------------------+\n",
        "Model name:          Intel(R) Xeon(R) CPU @ 2.20GHz\n",
        "Socket(s):           1\n",
        "Core(s) per socket:  1\n",
        "Thread(s) per core:  2\n",
        "L3 cache:            56320K\n",
        "CPU MHz:             2200.000\n",
        "13G\n",
        "Avail\n",
        "34G\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWPQqb3oETLd",
        "outputId": "850c845b-b1c7-4f81-d144-2391d7787686",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#GPU count and name\n",
        "!nvidia-smi -L\n",
        "\n",
        "#use this command to see GPU activity while doing Deep Learning tasks, for this command 'nvidia-smi' and for above one to work, go to 'Runtime > change runtime type > Hardware Accelerator > GPU'\n",
        "!nvidia-smi\n",
        "\n",
        "!lscpu |grep 'Model name'\n",
        "\n",
        "#no.of sockets i.e available slots for physical processors\n",
        "!lscpu | grep 'Socket(s):'\n",
        "\n",
        "#no.of cores each processor is having \n",
        "!lscpu | grep 'Core(s) per socket:'\n",
        "\n",
        "#no.of threads each core is having\n",
        "!lscpu | grep 'Thread(s) per core'\n",
        "\n",
        "!lscpu | grep \"L3 cache\"\n",
        "\n",
        "#if it had turbo boost it would've shown Min and Max MHz also but it is only showing current frequency this means it always operates at 2.3GHz\n",
        "!lscpu | grep \"MHz\"\n",
        "\n",
        "#memory that we can use\n",
        "!free -h --si | awk  '/Mem:/{print $2}'\n",
        "\n",
        "#hard disk space that we can use\n",
        "!df -h / | awk '{print $4}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: nvidia-smi: command not found\n",
            "/bin/bash: nvidia-smi: command not found\n",
            "Model name:                      Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "Socket(s):                       1\n",
            "Core(s) per socket:              1\n",
            "Thread(s) per core:              2\n",
            "L3 cache:                        55 MiB\n",
            "CPU MHz:                         2200.166\n",
            "12G\n",
            "Avail\n",
            "69G\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUA8ZfUsGIVs"
      },
      "source": [
        "# IMPORTANT: For every 12hrs or so Disk, RAM, VRAM, CPU cache etc data that is on our alloted virtual machine will get erased. MAKE SURE TO SAVE YOUR DATA.\n",
        "\n",
        "The following code cell runs some code for Tensorflow-gpu to ensure that it can access the colab GPU. The output should contain something similar to:\n",
        "\n",
        "```\n",
        "physical_device_desc: \"device: XLA_GPU device\"\n",
        ", name: \"/device:GPU:0\"\n",
        "device_type: \"GPU\"\n",
        "memory_limit: 15701463552\n",
        "locality {\n",
        "  bus_id: 1\n",
        "  links {\n",
        "  }\n",
        "}\n",
        "incarnation: 12081463421592476599\n",
        "physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n",
        "]\n",
        "``` "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "Ue4ODE-b7bLZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe7599c0-c63e-479b-a842-77f91fa6647f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/My Drive/Coursework/Spring 2023/289A Intro to ML/289A Project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lNAlWlU-Kba",
        "outputId": "a5558dad-af14-4e2c-a75f-2d7971e67b8b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/Coursework/Spring 2023/289A Intro to ML/289A Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hi23nWbEy6V",
        "outputId": "2d140aa2-6615-402d-8f2a-45fd1b59b8ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow.python.client import device_lib \n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 205680351718223895\n",
            "xla_global_id: -1\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCUuM_bQHMZt"
      },
      "source": [
        "The following command can be used as a bash command to monitor the usage and memory of your GPU.\n",
        "\n",
        "```\n",
        "!nvidia-smi\n",
        "```\n",
        "\n",
        "If you would like to monitor constant updates of the GPU, you can run the following for 1 second updates\n",
        "\n",
        "```\n",
        "!watch -n 1 nvidia-smi\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfPzGUoyHiLl",
        "outputId": "c7506ab7-83ed-4f09-e77b-deb967965e1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Apr 19 00:27:19 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P0    27W /  70W |    373MiB / 15360MiB |      2%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/My Drive/Coursework/Spring 2023/289A Intro to ML/289A Project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaRCFWKj6RBO",
        "outputId": "51adf502-bfa6-4b1f-9b69-db4a4e235852"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/Coursework/Spring 2023/289A Intro to ML/289A Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTa1iQlnHkOb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "outputId": "fe28f32e-c4c4-41af-b467-9cb603144152"
      },
      "source": [
        "#dependencies\n",
        "#Anaconda 3.6\n",
        "#Pytorch\n",
        "#Tensorboard\n",
        "#OpenCV python\n",
        "#torchvision\n",
        "#scipy\n",
        "import torch\n",
        "from math import ceil, sqrt\n",
        "import pickle\n",
        "import torch.nn as nn\n",
        "import os\n",
        "from torch.autograd import Variable\n",
        "# from skimage import io, transform\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import re\n",
        "# from tensorboardX import SummaryWriter\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import time\n",
        "from Neural_Network_Class import conv_deconv #Class where the network is defined\n",
        "import pdb, glob\n",
        "import scipy.io as spio\n",
        "\n",
        "load = 1\n",
        "train = 1\n",
        "test = 1\n",
        "tests_num = 1000\n",
        "writer = SummaryWriter('runs_hn')\n",
        "# once done, type in \"tensorboard --logdir=runs_hn --bind_all\" in terminal and go to the link being shown to visualize data\n",
        "\n",
        "class ImageDataset(Dataset): #Defining the class to load datasets\n",
        "\n",
        "    def __init__(self,input_dir,train=True):\n",
        "        self.input_dir=input_dir\n",
        "        self.train=train\n",
        "        self.pix_size = 71\n",
        "        self.current_datain=np.array([],dtype=np.float).reshape(0,self.pix_size,self.pix_size)\n",
        "        self.current_dataout=np.array([],dtype=np.float).reshape(0,self.pix_size,self.pix_size)\n",
        "        self.test_packts = 1\n",
        "        self.train_packts = len(glob.glob(self.input_dir+'/*.mat')) - self.test_packts\n",
        "    def __len__ (self):\n",
        "        if self.train:\n",
        "            return self.train_packts*2000 #I have kept size of testing data to be 50\n",
        "        else:\n",
        "            return self.test_packts*2000\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        if self.train:\n",
        "            if idx % 2000 == 0:\n",
        "                ind = (int(idx/2000))%(self.train_packts)+1\n",
        "                self.current_datain = spio.loadmat(self.input_dir+'/'+str(ind)+'.mat', squeeze_me=True)['tumorImage_withPSF']\n",
        "                self.current_dataout = spio.loadmat(self.input_dir+'/'+str(ind)+'.mat', squeeze_me=True)['tumorImage_noPSF']\n",
        "        else:\n",
        "             if idx % 2000 == 0:\n",
        "                ind = (int(idx/2000))%(self.test_packts)+1\n",
        "                print(self.input_dir+'/'+str(self.train_packts + ind)+'.mat')\n",
        "                self.current_datain =  spio.loadmat(self.input_dir+'/'+str(self.train_packts + ind)+'.mat', squeeze_me=True)['tumorImage_withPSF']\n",
        "                self.current_dataout = spio.loadmat(self.input_dir+'/'+str(self.train_packts + ind)+'.mat', squeeze_me=True)['tumorImage_noPSF']   \n",
        "        input_image= self.current_datain[idx%2000].reshape((1,self.pix_size,self.pix_size))     \n",
        "        input_image = (input_image - input_image.min())/(input_image.max()-input_image.min())\n",
        "        output_image=self.current_dataout[idx%2000].reshape((1,self.pix_size,self.pix_size))       \n",
        "        output_image = (output_image - output_image.min())/(output_image.max() - output_image.min())              \n",
        "\n",
        "        sample = {'input_image': input_image, 'output_image': output_image}             \n",
        "\n",
        "        return sample\n",
        "\n",
        "image_dir = \"/content/gdrive/My Drive/Coursework/Spring 2023/289A Intro to ML/289A Project/images\"\n",
        "# train_dataset=ImageDataset(input_dir=\"images\") #Training Dataset\n",
        "train_dataset=ImageDataset(input_dir=image_dir) #Training Dataset\n",
        "print(len(train_dataset))\n",
        "\n",
        "test_dataset=ImageDataset(input_dir=image_dir,train=False) #Testing Dataset\n",
        "batch_size = 250 #mini-batch size\n",
        "n_iters = 240 #total iterations\n",
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = ceil(num_epochs)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=False)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "# torch.cuda.set_device(device)\n",
        "# model=conv_deconv().cuda(1) # Neural network model object\n",
        "model=conv_deconv().to(device)\n",
        "\n",
        "iter=0\n",
        "iter_new=0 \n",
        "check=os.listdir(\"checkpoints\") #checking if checkpoints exist to resume training\n",
        "if load and len(check):\n",
        "    check.sort(key=lambda x:int((x.split('_')[2]).split('.')[0]))\n",
        "    model=torch.load(\"checkpoints/\"+check[-1],map_location=torch.device('cpu')).to(device)\n",
        "    iter=int(re.findall(r'\\d+',check[-1])[0])\n",
        "    iter_new=iter\n",
        "    print(\"Resuming from iteration \" + str(iter))\n",
        "    #os.system('python visualise.py')\n",
        "\n",
        "                                                                              # https://discuss.pytorch.org/t/can-t-import-torch-optim-lr-scheduler/5138/6 \n",
        "beg=time.time() #time at the beginning of training\n",
        "if train:\n",
        "    print(\"Training Started!\")\n",
        "    criterion=nn.MSELoss() #.cuda(1)  #Loss Class\n",
        "        \n",
        "    learning_rate = 0.005\n",
        "    optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate) #optimizer class\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)# this will decrease the learning rate by factor of 0.1\n",
        "    for epoch in range(num_epochs):\n",
        "        print(\"\\nEPOCH \" +str(epoch+1)+\" of \"+str(num_epochs)+\"\\n\")\n",
        "        for i,datapoint in enumerate(train_loader):\n",
        "            datapoint['input_image']=datapoint['input_image'].type(torch.FloatTensor) #typecasting to FloatTensor as it is compatible with CUDA\n",
        "            datapoint['output_image']=datapoint['output_image'].type(torch.FloatTensor)\n",
        "            # input_image = Variable(datapoint['input_image'].cuda(1)) #Converting a Torch Tensor to Autograd Variable\n",
        "            input_image = Variable(datapoint['input_image']) #.cuda(0)) #Converting a Torch Tensor to Autograd Variable\n",
        "            # output_image = Variable(datapoint['output_image'].cuda(1))\n",
        "            output_image = Variable(datapoint['output_image']) #.cuda(0))\n",
        "            \n",
        "            optimizer.zero_grad()  #https://discuss.pytorch.org/t/why-do-we-need-to-set-the-gradients-manually-to-zero-in-pytorch/4903/3\n",
        "            outputs = model(input_image)\n",
        "            # loss = criterion(outputs.to(torch.device('cpu')), output_image)\n",
        "            # loss = criterion(outputs, output_image.cuda(1))\n",
        "            loss = criterion(outputs, output_image) #.cuda(0))\n",
        "            loss.backward() #Backprop\n",
        "            optimizer.step()    #Weight update\n",
        "            writer.add_scalar('Training Loss',loss.data.item(), iter)\n",
        "            iter=iter+1\n",
        "            if iter % 25 == 0 or iter==1:\n",
        "                # Calculate Accuracy         \n",
        "                test_loss = 0\n",
        "                total = 0\n",
        "                # Iterate through test dataset\n",
        "                for j,datapoint_1 in enumerate(test_loader): #for testing\n",
        "                    datapoint_1['input_image']=datapoint_1['input_image'].type(torch.FloatTensor)\n",
        "                    datapoint_1['output_image']=datapoint_1['output_image'].type(torch.FloatTensor)\n",
        "                \n",
        "                    input_image_1 = Variable(datapoint_1['input_image']) #.cuda(1))\n",
        "                    output_image_1 = Variable(datapoint_1['output_image']) #.cuda(1))\n",
        "                    \n",
        "                    # Forward pass only to get logits/output\n",
        "                    outputs = model(input_image_1)\n",
        "                    test_loss += criterion(outputs, output_image_1).data.item()\n",
        "                    total+=1 # datapoint_1['output_image'].size(0)\n",
        "                test_loss= test_loss/total   #sum of test loss for all test cases/total cases\n",
        "                writer.add_scalar('Test Loss',test_loss, iter) \n",
        "                # Print Loss\n",
        "                time_since_beg=(time.time()-beg)/60\n",
        "                print('Iteration: {}. Loss: {}. Test Loss: {}. Time(mins) {}'.format(iter, loss.data.item(), test_loss,time_since_beg))\n",
        "            if iter % 500 ==0:\n",
        "                torch.save(model,'checkpoints/model_iter_'+str(iter)+'.pt')\n",
        "                print(\"model saved at iteration : \"+str(iter))\n",
        "                # writer.export_scalars_to_json(\"runs_hn/scalars.json\") #saving loss vs iteration data to be used by visualise.py\n",
        "        scheduler.step()        \n",
        "    writer.close()          \n",
        "\n",
        "if test:\n",
        "    iter = 0\n",
        "    print('Testing the %d first samples'%tests_num)\n",
        "    fig = plt.figure(figsize=(30,30))\n",
        "    #input_imgs = zeros(71,71,test_num)\n",
        "    #output_imgs = zeros(71,71,test_num)\n",
        "    #true_outs = zeros(71,71,test_num)\n",
        "    #input_psf = zeros(71,71,test_num)\n",
        "    #output_psf = zeros(71,71,test_num)\n",
        "    for i in range(tests_num):\n",
        "        # Calculate Accuracy  \n",
        "        datapoint_1 = test_dataset[i]\n",
        "        datapoint_1['input_image']=torch.tensor(datapoint_1['input_image']).type(torch.FloatTensor)\n",
        "        datapoint_1['output_image']=torch.tensor(datapoint_1['output_image']).type(torch.FloatTensor)\n",
        "   \n",
        "        if torch.cuda.is_available():\n",
        "            input_image_1 = Variable(datapoint_1['input_image'].to(device))\n",
        "            output_image_1 = Variable(datapoint_1['output_image'].to(torch.device('cpu')))\n",
        "        else:\n",
        "            input_image_1 = Variable(datapoint_1['input_image'])\n",
        "            output_image_1 = Variable(datapoint_1['output_image'])\n",
        "        \n",
        "        outputs = model(input_image_1.reshape((1,1,71,71)))\n",
        "        point_src = outputs*0\n",
        "        point_src[0,0,36,36] = 1\n",
        "        PSF = model(point_src).reshape((71,71))\n",
        "        point_src = ((point_src.cpu()).reshape((71,71))).data.numpy()\n",
        "        PSF = (PSF.cpu()).data.numpy()\n",
        "        time_since_beg=(time.time()-beg)/60\n",
        "        print('Iteration: {}. Time(mins) {}'.format(iter, time_since_beg))           \n",
        "        # plt.subplot(221)\n",
        "        # plt.imshow(((input_image_1.cpu()).reshape((71,71))).data.numpy())\n",
        "        # plt.subplot(222)\n",
        "        # plt.imshow(((outputs.cpu()).reshape((71,71))).data.numpy())\n",
        "        # plt.subplot(224)\n",
        "        # plt.imshow(((output_image_1.cpu()).reshape((71,71))).data.numpy())\n",
        "        # plt.savefig('test_results/' + str(iter) + '.png') \n",
        "        iter = iter + 1  \n",
        "        spio.savemat('test_results/data_'+ str(iter) + '.mat', {     'input_image':((input_image_1.cpu()).reshape((71,71))).data.numpy(),\n",
        "                                                        'output':((outputs.cpu()).reshape((71,71))).data.numpy(),\n",
        "                                                        'gnd_truth':((output_image_1.cpu()).reshape((71,71))).data.numpy()})\n",
        "    plt.close('all')\n",
        "    fig = plt.figure(figsize=(30,30))\n",
        "    plt.subplot(121)\n",
        "    plt.imshow(point_src)\n",
        "    plt.subplot(122)\n",
        "    plt.imshow(PSF)\n",
        "    plt.savefig('test_results/PSF' + '.png')\n",
        "    plt.close('all')\n",
        "\n",
        "writer.close()\n",
        "#decrease learning rate"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-2ee83003954d>:41: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  self.current_datain=np.array([],dtype=np.float).reshape(0,self.pix_size,self.pix_size)\n",
            "<ipython-input-30-2ee83003954d>:42: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  self.current_dataout=np.array([],dtype=np.float).reshape(0,self.pix_size,self.pix_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18000\n",
            "test18000\n",
            "Training Started!\n",
            "\n",
            "EPOCH 1 of 4\n",
            "\n",
            "/content/gdrive/My Drive/Coursework/Spring 2023/289A Intro to ML/289A Project/images/10.mat\n",
            "Iteration: 1. Loss: 0.01691884733736515. Test Loss: 0.014308645972050726. Time(mins) 0.21441726287206014\n",
            "/content/gdrive/My Drive/Coursework/Spring 2023/289A Intro to ML/289A Project/images/10.mat\n",
            "Iteration: 25. Loss: 0.005788101349025965. Test Loss: 0.0056763505563139915. Time(mins) 0.8415995438893636\n",
            "/content/gdrive/My Drive/Coursework/Spring 2023/289A Intro to ML/289A Project/images/10.mat\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-2ee83003954d>\u001b[0m in \u001b[0;36m<cell line: 110>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;31m# Iterate through test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdatapoint_1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#for testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                     \u001b[0mdatapoint_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatapoint_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0mdatapoint_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output_image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatapoint_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output_image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2ee83003954d>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_packts\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_datain\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mspio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_packts\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqueeze_me\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tumorImage_withPSF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_dataout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_packts\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqueeze_me\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tumorImage_noPSF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0minput_image\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_datain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpix_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpix_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0minput_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minput_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/scipy/io/matlab/_mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmdict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/scipy/io/matlab/_mio5.py\u001b[0m in \u001b[0;36mget_variables\u001b[0;34m(self, variable_names)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_var_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhdr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mMatReadError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 warnings.warn(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/scipy/io/matlab/_mio5.py\u001b[0m in \u001b[0;36mread_var_array\u001b[0;34m(self, header, process)\u001b[0m\n\u001b[1;32m    290\u001b[0m            \u001b[0;31m`\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         '''\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matrix_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_from_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m_mio5_utils.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.array_from_header\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_mio5_utils.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.array_from_header\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_mio_utils.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab._mio_utils.squeeze_element\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_mio_utils.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab._mio_utils.squeeze_element\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36msqueeze\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "metadata": {
        "id": "vgteTDk6_r1B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7bacea3-a295-4607-afff-7e8e0ea63fae"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "rgAuaVuG-4rF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " !ls /content/gdrive/My\\ Drive/_2022:23/_SP23/'1 CS289A - Intro to ML'/project/code/images\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-prxxfDgw1x",
        "outputId": "21cbcaf9-29d4-4098-fc54-3b96ef8c0886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.mat\t1.mat  2.mat  3.mat  4.mat  5.mat  6.mat  7.mat  8.mat\t9.mat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EaVK185Ng18O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}